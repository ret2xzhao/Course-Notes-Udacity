1
00:00:00,000 --> 00:00:04,530
我们已经讨论过神经网络如何从数据中“学习”

2
00:00:04,530 --> 00:00:07,210
那么你可能想知道这种学习如何发生

3
00:00:07,209 --> 00:00:09,599
学习有时称为训练

4
00:00:09,599 --> 00:00:12,469
它由三步循环组成

5
00:00:12,470 --> 00:00:17,024
前馈、误差测定和反向传播

6
00:00:17,024 --> 00:00:20,250
首先随机分配初始权重

7
00:00:20,250 --> 00:00:23,204
即人工神经元的值

8
00:00:23,204 --> 00:00:28,625
通过神经网络来馈送每个图像 产生输出值

9
00:00:28,625 --> 00:00:31,155
这被称为前馈

10
00:00:31,155 --> 00:00:33,785
下一步为误差测定

11
00:00:33,784 --> 00:00:36,059
误差是真值标记与

12
00:00:36,060 --> 00:00:41,480
与前馈过程所产生输出之间的偏差 

13
00:00:41,479 --> 00:00:44,609
最后一步是反向传播

14
00:00:44,609 --> 00:00:46,920
通过神经网络反向发送误差

15
00:00:46,920 --> 00:00:51,300
此过程类似前馈过程 只是以相反方向进行

16
00:00:51,299 --> 00:00:54,419
每个人工神经元都对其值进行微调

17
00:00:54,420 --> 00:00:59,515
这是基于通过神经网络后向传播的误差

18
00:00:59,515 --> 00:01:04,859
所有这些独立调整的结果 可生成更准确的网络 

19
00:01:04,859 --> 00:01:08,295
一个训练周期： 包括前馈

20
00:01:08,295 --> 00:01:11,965
误差测定和反向传播还远远不够

21
00:01:11,965 --> 00:01:18,000
为了训练网络 通常需要数千个这样的周期

22
00:01:18,000 --> 00:01:20,859
但最终结果应该是

23
00:01:20,859 --> 00:01:24,359
模型能够根据新数据做出准确预测

