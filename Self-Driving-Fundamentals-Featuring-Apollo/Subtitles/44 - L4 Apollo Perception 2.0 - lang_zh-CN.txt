1
00:00:00,000 --> 00:00:04,835
Apollo 开放式软件栈可感知障碍物

2
00:00:04,835 --> 00:00:07,290
交通信号灯和车道

3
00:00:07,290 --> 00:00:09,960
对于三维对象检测

4
00:00:09,960 --> 00:00:12,655
Apollo 在高精度地图上使用感兴趣区域 (ROI) 

5
00:00:12,654 --> 00:00:17,894
来重点关注相关对象

6
00:00:17,894 --> 00:00:22,824
Apollo 将 ROI 过滤器应用于点云和图像数据

7
00:00:22,824 --> 00:00:26,719
以缩小搜索范围并加快感知

8
00:00:26,719 --> 00:00:31,304
然后 通过检测网络馈送已过滤的点云

9
00:00:31,304 --> 00:00:37,664
输出用于构建围绕对象的三维边界框

10
00:00:37,664 --> 00:00:40,850
最后 我们使用被称为检测跟踪关联的算法

11
00:00:40,850 --> 00:00:47,539
来跨时间步识别单个对象 

12
00:00:47,539 --> 00:00:52,280
该算法先保留在每个时间步要跟踪的对象列表

13
00:00:52,280 --> 00:00:57,020
然后在下一个时间步中找到每个对象的最佳匹配

14
00:00:57,020 --> 00:00:59,260
对于交通信号灯的分类

15
00:00:59,259 --> 00:01:04,894
Apollo 先使用高精度地图来确定前方是否存在交通信号灯

16
00:01:04,894 --> 00:01:07,454
如果前方有交通信号灯

17
00:01:07,454 --> 00:01:10,784
则高精度地图会返回灯的位置

18
00:01:10,784 --> 00:01:13,799
这侧重于摄像头搜索范围

19
00:01:13,799 --> 00:01:17,439
在摄像头捕获到交通信号灯图像后

20
00:01:17,439 --> 00:01:22,274
Apollo 使用检测网络对图像中的灯进行定位

21
00:01:22,275 --> 00:01:27,070
然后 Apollo 从较大的图像中提取交通信号灯

22
00:01:27,069 --> 00:01:29,739
Apollo 将裁剪的交通灯图像提供给分类网络

23
00:01:29,739 --> 00:01:33,765
以确定灯颜色

24
00:01:33,765 --> 00:01:36,070
如果有许多灯

25
00:01:36,069 --> 00:01:40,769
则系统需要选择哪些灯与其车道相关

26
00:01:40,769 --> 00:01:44,140
Apollo 使用 YOLO 网络

27
00:01:44,140 --> 00:01:47,719
来检测车道线和动态物体 其中包括车辆

28
00:01:47,719 --> 00:01:50,870
卡车、骑自行车的人和行人

29
00:01:50,870 --> 00:01:53,329
在经过 YOLO 网络检测后

30
00:01:53,329 --> 00:01:56,609
在线检测模块会并入来自其他传感器的数据

31
00:01:56,609 --> 00:02:00,530
对车道线预测进行调整

32
00:02:00,530 --> 00:02:03,180
车道线最终被并入名为

33
00:02:03,180 --> 00:02:06,665
“虚拟车道”的单一数据结构中

34
00:02:06,665 --> 00:02:09,930
同样 也通过其他传感器的数据

35
00:02:09,930 --> 00:02:15,450
对 YOLO 网络所检测到的动态对象进行调整

36
00:02:15,449 --> 00:02:19,274
以获得每个对象的类型、位置、速度和前进方向

37
00:02:19,275 --> 00:02:21,750
虚拟通道和动态对象

38
00:02:21,750 --> 00:02:27,479
均被传递到规划与控制模块

