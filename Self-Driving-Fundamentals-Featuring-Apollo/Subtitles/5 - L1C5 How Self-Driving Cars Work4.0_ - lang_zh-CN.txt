1
00:00:09,080 --> 00:00:10,320
大家好

2
00:00:10,320 --> 00:00:11,470
你好

3
00:00:12,760 --> 00:00:17,840
我在优达学城负责无人驾驶车纳米学位课程

4
00:00:17,840 --> 00:00:20,200
这个课程为期九个月

5
00:00:20,200 --> 00:00:23,170
为软件工程师提供无人驾驶车方面的培训

6
00:00:23,170 --> 00:00:28,630
在来到优达学城任教之前 我实际上也是优达学城的一名学员

7
00:00:28,630 --> 00:00:33,490
我曾工作多年 是一名普通的硅谷网络软件工程师 从事开发 Ruby on Rails

8
00:00:33,490 --> 00:00:38,370
几年前我开始对无人驾驶车感兴趣

9
00:00:38,370 --> 00:00:44,340
但却没有机器人或系统软件或汽车软件方面的背景知识

10
00:00:44,340 --> 00:00:47,505
于是 我开始在优达学城和其他网站上学在线课程

11
00:00:47,505 --> 00:00:51,375
学习如何成为一名无人驾驶汽车工程师

12
00:00:51,375 --> 00:00:54,360
后来 我来到了福特汽车公司位于加利福尼亚州帕洛阿尔托的研究与创新中心

13
00:00:54,360 --> 00:00:58,380
加入了其无人驾驶车团队

14
00:00:58,380 --> 00:01:03,420
后来 优达学城的团队邀请我

15
00:01:03,420 --> 00:01:06,420
开设一个课程

16
00:01:06,420 --> 00:01:10,550
帮助那些像我一样的人成为无人驾驶汽车工程师

17
00:01:10,980 --> 00:01:14,925
在优达学城 我们拥有自己的无人驾驶汽车

18
00:01:14,925 --> 00:01:16,830
她的名字是 Carla

19
00:01:16,830 --> 00:01:20,280
我想告诉你一些

20
00:01:20,280 --> 00:01:23,250
关于 Carla 如何工作以及大多数无人驾驶车

21
00:01:23,250 --> 00:01:25,890
是如何通过一些项目一步步实现的

22
00:01:25,890 --> 00:01:30,045
而我们的学员已经在纳米学位课程中完成了这些项目

23
00:01:30,045 --> 00:01:35,925
我认为 无人驾驶车包括五个核心部件

24
00:01:35,925 --> 00:01:39,375
计算机视觉 传感器融合

25
00:01:39,375 --> 00:01:44,770
定位 路径规划以及控制

26
00:01:44,770 --> 00:01:48,240
计算机视觉就是我们通过摄像头图像

27
00:01:48,240 --> 00:01:51,780
弄清楚我们周围的世界是怎样的

28
00:01:51,780 --> 00:01:55,530
传感器融合是我们合并来自其他传感器的数据 如激光和雷达

29
00:01:55,530 --> 00:02:00,405
从而更加深入地了解我们周围的环境

30
00:02:00,405 --> 00:02:05,050
只要我们对周围的世界有了深刻的理解

31
00:02:05,050 --> 00:02:08,820
就可以使用定位来精确地确定我们在那个世界所处的位置

32
00:02:08,820 --> 00:02:11,520
然后 只要我们能弄清楚我们在那个世界的具体位置

33
00:02:11,520 --> 00:02:14,790
那个世界的环境

34
00:02:14,790 --> 00:02:18,840
我们就可以使用路径规划来绘制这个世界的路线 

35
00:02:18,840 --> 00:02:22,955
帮助我们到达我们想去的地方 然后 最后一步是控制

36
00:02:22,955 --> 00:02:26,740
控制就是我们为了让汽车沿着我们在路径规划期间建立的轨道 

37
00:02:26,740 --> 00:02:31,700
如何转动方向盘并打开油门 然后踩刹车

38
00:02:31,700 --> 00:02:34,330
这就是无人驾驶汽车的五个核心部分

39
00:02:34,330 --> 00:02:38,190
接下来 我想和你们一起研究一下

40
00:02:38,190 --> 00:02:40,375
这是计算机视觉

41
00:02:40,375 --> 00:02:43,810
这是一部 Carla 在硅谷280号高速公路上行驶的视频

42
00:02:43,810 --> 00:02:48,625
它是我们的一个学员 Vivek Adab 的作品

43
00:02:48,625 --> 00:02:50,920
Vivek 正在使用计算机视觉

44
00:02:50,920 --> 00:02:54,180
寻找颜色、边缘以及渐变色 

45
00:02:54,180 --> 00:02:56,310
从而定义这条公路上的车道

46
00:02:56,310 --> 00:03:00,750
之前 他已经对一个深度神经网络进行训练 使其绘制道路上其他车辆周围的边界框

47
00:03:00,750 --> 00:03:02,820
深度神经网络或深度学习

48
00:03:02,820 --> 00:03:06,480
是人工智能领域机器学习的新的组成部分

49
00:03:06,480 --> 00:03:09,180
通过这个网络 只需简单地发送大量的数据

50
00:03:09,180 --> 00:03:12,770
电脑就可以识别汽车以及其他对象

51
00:03:12,770 --> 00:03:15,690
它们看到很多汽车 知道汽车的外观

52
00:03:15,690 --> 00:03:18,640
正如你所看到的 深度神经网络在试图弄清楚具体是一辆车

53
00:03:18,640 --> 00:03:20,545
两辆车 它们是否是分开的

54
00:03:20,545 --> 00:03:24,060
还是几辆汽车 

55
00:03:24,060 --> 00:03:28,480
这与今天公路上的高级辅助驾驶系统所做的事情类似

56
00:03:28,840 --> 00:03:33,820
所以 一旦我们通过摄像头图像知道了某个世界的外观

57
00:03:33,820 --> 00:03:36,640
下一步就是使用其他传感器增加对这个世界的理解

58
00:03:36,640 --> 00:03:40,810
如雷达和激光器

59
00:03:40,810 --> 00:03:43,680
获得摄像头很难测量到的测量值

60
00:03:43,680 --> 00:03:47,070
从而搞清楚很多信息 如 我们与其他汽车之间的距离

61
00:03:47,070 --> 00:03:51,390
周围其他物体的移动速度 

62
00:03:51,390 --> 00:03:55,980
你现在看到的是 Carla 使用 El Camino Real 获取的数据

63
00:03:55,980 --> 00:04:00,660
这个地方是硅谷的主要商业街 

64
00:04:00,660 --> 00:04:05,655
在右侧 你可以通过视频看到这次行驶的全过程 这里的主图像

65
00:04:05,655 --> 00:04:10,950
是对 Carla 周围的世界的激光扫描 

66
00:04:10,950 --> 00:04:14,580
你可以看到 

67
00:04:14,580 --> 00:04:16,380
这个激光阵列是激光雷达对周围世界的一个360度扫描

68
00:04:16,380 --> 00:04:20,200
从上面可以看到这个环境中不同物体的外观 以及它们是如何移动的

69
00:04:20,680 --> 00:04:27,090
所以说 只要我们知道了这个世界是什么样子的 以及如何测量它

70
00:04:27,090 --> 00:04:29,190
就可以将这些信息结合在一起

71
00:04:29,190 --> 00:04:32,550
从而得到一个关于我们周围环境的丰富画面

72
00:04:32,550 --> 00:04:36,095
下一步就是在那个环境中定位自己

73
00:04:36,095 --> 00:04:39,490
你可能会认为这很简单 因为今天我们都有手机

74
00:04:39,490 --> 00:04:41,025
手机上都拥有 GPS

75
00:04:41,025 --> 00:04:43,680
我们都知道我们所处的位置

76
00:04:43,680 --> 00:04:46,200
但事实上 GPS 只能精确到大约一米到两米

77
00:04:46,200 --> 00:04:51,270
你可能会想 一米到两米到底有多远

78
00:04:51,270 --> 00:04:53,700
如果一辆汽车的行驶位置错了一到两米

79
00:04:53,700 --> 00:04:57,935
那它可能跑到人行道上撞到物体了

80
00:04:57,935 --> 00:05:00,640
那不就糟糕了吗 

81
00:05:00,640 --> 00:05:03,010
所以 我们要用更复杂的数学算法

82
00:05:03,010 --> 00:05:05,530
以及高清晰度地图

83
00:05:05,530 --> 00:05:07,660
来定位我们的车辆正好位于它的环境中

84
00:05:07,660 --> 00:05:13,250
准确度要精确到一位数厘米级别 这个就是我们的一个学员所做的事情

85
00:05:13,250 --> 00:05:16,580
他的名字是Daniel Lopez Madrid 他正在做的是

86
00:05:16,580 --> 00:05:18,960
使用一个粒子滤波器

87
00:05:18,960 --> 00:05:21,435
一个非常复杂的三角测量类型

88
00:05:21,435 --> 00:05:25,050
当他的蓝色车辆在模拟器中移动时

89
00:05:25,050 --> 00:05:27,900
这个滤波器就会测量它与各种地标之间的距离

90
00:05:27,900 --> 00:05:30,810
它要弄清楚这些地标距离它有多远 在哪里会看到地标

91
00:05:30,810 --> 00:05:34,740
并将其与地图进行比较 然后找出它在那个世界的准确位置

92
00:05:34,740 --> 00:05:39,010
这就是无人驾驶车的定位方式

93
00:05:39,010 --> 00:05:42,810
在现实世界中 这些地标可能是路灯之类的东西

94
00:05:42,810 --> 00:05:48,070
或交通标志或邮筒 甚至是井盖

95
00:05:48,610 --> 00:05:51,910
我们知道了我们处于这个世界的哪个位置

96
00:05:51,910 --> 00:05:54,910
以及周围的环境是什么样子之后

97
00:05:54,910 --> 00:05:58,240
下一步 就是要真正去规划一条通过这个世界的路径

98
00:05:58,240 --> 00:06:02,370
找到如何才能到达我们想要去的地方 这就是路径规划

99
00:06:02,370 --> 00:06:06,235
在这里 你可以看到我们的一个学员 Kazahiro Nakagawa 的作品

100
00:06:06,235 --> 00:06:10,620
Kazahiro 所做的就是在我们的优达学城高速公路模拟器中

101
00:06:10,620 --> 00:06:13,210
建立一个路径规划器

102
00:06:13,210 --> 00:06:16,600
用来预测道路上的其他车辆去向 

103
00:06:16,600 --> 00:06:19,480
然后推算出他的车辆应该采取何种回应措施

104
00:06:19,480 --> 00:06:22,750
然后最终建立一系列路径点

105
00:06:22,750 --> 00:06:25,150
也就是你在视频中看到的那些绿色珍珠

106
00:06:25,150 --> 00:06:27,900
汽车穿过这些路径点就可以了 

107
00:06:27,900 --> 00:06:31,200
这也就是汽车应该行驶的轨道 你看 他的车辆遇到其他交通工具时

108
00:06:31,200 --> 00:06:34,155
它必须弄清楚是否应该放缓速度并保持其状态

109
00:06:34,155 --> 00:06:37,500
或者它应该向右移位还是向左移位

110
00:06:37,500 --> 00:06:40,425
这实际上就是无人驾驶车必须做出的决定类型

111
00:06:40,425 --> 00:06:44,640
所有这些都受限于速度限制和加速限制等约束条件

112
00:06:44,640 --> 00:06:46,710
从而让乘客在这个行驶过程拥有舒适的体验

113
00:06:46,710 --> 00:06:48,810
你可以想象得到 在城市中行驶时 一切会变得更加复杂

114
00:06:48,810 --> 00:06:52,980
因为那里的马路交叉点太多 你需要推算和考虑的也会更多

115
00:06:52,980 --> 00:06:56,010
但原则上 都是一样的

116
00:06:56,010 --> 00:07:00,690
然后 我们找到了通过这个世界要采取的路径

117
00:07:00,690 --> 00:07:02,610
我们知道我们在哪里

118
00:07:02,610 --> 00:07:04,620
知道这个世界是什么样的

119
00:07:04,620 --> 00:07:07,810
接下来的最后一步 就是控制

120
00:07:07,810 --> 00:07:12,570
控制就是我们如何转动方向盘 打开油门 并踩下制动器

121
00:07:12,570 --> 00:07:18,190
从而使汽车沿着我们在路径规划期间建立的轨道行驶

122
00:07:18,190 --> 00:07:21,735
你看 这是我们的另一个学员学员 Emmy Lowe

123
00:07:21,735 --> 00:07:25,570
这是优达学城的跑道模拟器 上面有一条黄线

124
00:07:25,570 --> 00:07:29,440
这是她的汽车应遵循的理想轨迹 

125
00:07:29,440 --> 00:07:32,680
你能看到 有一条绿线分布在黄线之上

126
00:07:32,680 --> 00:07:35,920
这条绿线就是她的车辆根据方向盘、油门以及制动命令

127
00:07:35,920 --> 00:07:40,150
预测它将遵循的轨迹

128
00:07:40,150 --> 00:07:45,580
而我们希望的是 绿线与黄线完全重合

129
00:07:45,580 --> 00:07:49,320
当然 这很难 开过车的人可能都知道这一点

130
00:07:49,320 --> 00:07:52,315
特别是在急转弯时 你真的很难完全沿着那条线

131
00:07:52,315 --> 00:07:55,719
也就是你想要沿着的车道中间的那条线

132
00:07:55,719 --> 00:07:57,290
但你做得已经很好了

133
00:07:57,290 --> 00:07:59,320
毕竟你在努力做到 事实上

134
00:07:59,320 --> 00:08:02,740
电脑却很擅长这个 它们想要遵循的轨迹

135
00:08:02,740 --> 00:08:07,230
与它们实际遵循的轨迹之间的距离 真的非常接近

136
00:08:07,230 --> 00:08:11,410
所以 这就是无人驾驶汽车的高水平驾驶

137
00:08:11,410 --> 00:08:14,500
我们使用计算机视觉和传感器融合

138
00:08:14,500 --> 00:08:18,000
获取一幅关于我们在世界上的位置的丰富画面

139
00:08:18,000 --> 00:08:24,070
使用定位确定我们在这个世界的精确位置

140
00:08:24,070 --> 00:08:26,680
然后 使用路径规划来绘制

141
00:08:26,680 --> 00:08:30,250
一条通过这个世界到达目的地的路径 

142
00:08:30,250 --> 00:08:33,580
然后 通过控制转动方向盘 打开油门 然后踩制动器

143
00:08:33,580 --> 00:08:37,405
沿着该轨迹行驶 并最终移动车辆

144
00:08:37,405 --> 00:08:40,240
从本质上讲 其他一切无人驾驶车

145
00:08:40,240 --> 00:08:42,205
都是这些核心功能更复杂的实现 

146
00:08:42,205 --> 00:08:45,865
以上就是无人驾驶车的工作原理

147
00:08:45,865 --> 00:08:49,195
从事无人驾驶车的研发 是一件令人激动的事

148
00:08:49,195 --> 00:08:51,850
计算机在这些任务中做得越来越好

149
00:08:51,850 --> 00:08:55,600
我希望你很快就能看到 你附近的道路上将出现很多无人驾驶车

150
00:08:55,600 --> 00:08:57,140
我是 David Silver

151
00:08:57,140 --> 00:09:01,180
我在优达学城负责无人驾驶车课程 非常感谢大家

