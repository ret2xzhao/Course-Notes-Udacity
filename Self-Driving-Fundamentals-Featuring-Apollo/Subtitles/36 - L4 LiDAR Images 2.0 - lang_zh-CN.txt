1
00:00:00,000 --> 00:00:04,875
感知扩展到传感器 而不仅仅是摄像头

2
00:00:04,875 --> 00:00:09,460
激光雷达传感器创建环境的点云表征

3
00:00:09,460 --> 00:00:12,360
提供了难以通过摄像头图像获得的信息

4
00:00:12,359 --> 00:00:16,425
如距离和高度

5
00:00:16,425 --> 00:00:18,769
激光雷达传感器使用光线 

6
00:00:18,769 --> 00:00:21,870
尤其是激光 来测量

7
00:00:21,870 --> 00:00:26,250
与环境中反射该光线的物体之间的距离

8
00:00:26,250 --> 00:00:30,089
激光雷达发射激光脉冲并测量物体

9
00:00:30,089 --> 00:00:34,509
将每个激光脉冲反射回传感器所花费的时间

10
00:00:34,509 --> 00:00:40,214
反射需要的时间越长 物体离传感器越远

11
00:00:40,215 --> 00:00:44,600
激光雷达正是通过这种方式来构建世界的视觉表征

12
00:00:44,600 --> 00:00:48,740
你可以在此可视化视图中看到激光雷达的输出

13
00:00:48,740 --> 00:00:53,469
激光雷达通过发射光脉冲来检测汽车周围的环境

14
00:00:53,469 --> 00:00:58,109
蓝色点表示反射激光脉冲的物体

15
00:00:58,109 --> 00:01:04,424
中间的黑色区域是无人驾驶车本身占据的空间

16
00:01:04,424 --> 00:01:08,375
由于激光雷达测量激光束反射

17
00:01:08,375 --> 00:01:13,125
它收集的数据形成一团点或“点云”

18
00:01:13,125 --> 00:01:19,890
点云中的每个点代表反射回传感器的激光束

19
00:01:19,890 --> 00:01:22,859
这些点云可以告诉我们关于物体的许多信息

20
00:01:22,859 --> 00:01:27,120
例如其形状和表面纹理

21
00:01:27,120 --> 00:01:29,984
通过对点进行聚类和分析

22
00:01:29,984 --> 00:01:33,299
这些数据提供了足够的对象检测、

23
00:01:33,299 --> 00:01:36,605
跟踪或分类信息

24
00:01:36,605 --> 00:01:43,300
在这里你可以看到在点云上执行的检测和分类结果

25
00:01:43,299 --> 00:01:49,424
红点为行人 绿点表示其他汽车

26
00:01:49,424 --> 00:01:52,375
正如你所看到的那样 激光雷达数据提供了

27
00:01:52,375 --> 00:01:57,899
用于构建世界视觉表征的足够空间信息

28
00:01:57,899 --> 00:02:01,739
计算机视觉技术不仅可以使用摄像头图像进行对象分类 

29
00:02:01,739 --> 00:02:07,719
还可以使用点云和其他类型的空间相关数据进行对象分类

