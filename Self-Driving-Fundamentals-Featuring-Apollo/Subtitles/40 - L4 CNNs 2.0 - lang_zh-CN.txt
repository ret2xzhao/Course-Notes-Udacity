1
00:00:00,000 --> 00:00:04,559
卷积神经网络 （CNN） 是

2
00:00:04,559 --> 00:00:09,914
一种人工神经网络 它对感知问题特别有效

3
00:00:09,914 --> 00:00:14,339
CNN 接受多维输入

4
00:00:14,339 --> 00:00:20,085
包括定义大多数传感器数据的二维和三维形状

5
00:00:20,085 --> 00:00:25,380
如果使用标准神经网络对图像进行分类

6
00:00:25,379 --> 00:00:27,890
则需要通过一种方法将图像连接到网络的第一层

7
00:00:27,890 --> 00:00:31,370
这属于一维

8
00:00:31,370 --> 00:00:37,429
标准做法是通过将图像矩阵重塑为一个矢量

9
00:00:37,429 --> 00:00:43,700
并在一个大行中连接所有列 将图像“展开”为一维像素阵列  

10
00:00:43,700 --> 00:00:49,255
然而 这种方法打破了图像中所嵌入的空间信息

11
00:00:49,255 --> 00:00:51,580
如果图像中有车轮

12
00:00:51,579 --> 00:00:55,875
则车轮中的所有像素将散布在整个像素阵列中

13
00:00:55,875 --> 00:00:58,835
但我们知道 这些像素

14
00:00:58,835 --> 00:01:01,939
以二维方式连接形成车轮

15
00:01:01,939 --> 00:01:04,429
如果我们将其散布在一个维度上

16
00:01:04,430 --> 00:01:08,755
神经网络很难从图像中提取车轮

17
00:01:08,754 --> 00:01:15,439
CNN 通过维持输入像素之间的空间关系来解决这个问题

18
00:01:15,439 --> 00:01:18,530
具体来说 CNN 通过将

19
00:01:18,530 --> 00:01:23,045
过滤器连续滑过图像来收集信息

20
00:01:23,045 --> 00:01:25,670
每次收集信息时

21
00:01:25,670 --> 00:01:29,585
只对整个图像的一小部分区域进行分析 

22
00:01:29,584 --> 00:01:32,269
这被称为“卷积”

23
00:01:32,269 --> 00:01:36,939
当我们在整个输入图像上对一个过滤器进行“卷积”时

24
00:01:36,939 --> 00:01:40,545
我们将该信息与下一个卷积层相关联

25
00:01:40,545 --> 00:01:45,790
例如 CNN 可以识别第一个卷积层中的基本边缘和颜色信息

26
00:01:45,790 --> 00:01:52,180
然后 通过在第一层上卷积新过滤器

27
00:01:52,180 --> 00:01:56,260
CNN 可以使用边缘和颜色信息

28
00:01:56,260 --> 00:02:01,853
来归纳更复杂的结构 如车轮、车门和挡风玻璃

29
00:02:01,853 --> 00:02:05,469
而另一个卷积可使用车轮、车门

30
00:02:05,469 --> 00:02:09,039
和挡风玻璃识别整个车辆

31
00:02:09,039 --> 00:02:11,400
最后 神经网络可使用

32
00:02:11,400 --> 00:02:15,659
这一高阶信息对车辆进行分类

33
00:02:15,659 --> 00:02:21,210
人们通常不太清楚 CNN 如何解读图像

34
00:02:21,210 --> 00:02:24,844
CNN 有时会侧重于图像中令人惊讶的部分

35
00:02:24,844 --> 00:02:27,460
但这也是深度学习的神奇之处

36
00:02:27,460 --> 00:02:32,915
CNN 根据其任务查找真正需要的特征

37
00:02:32,914 --> 00:02:36,639
任务可能是图像检测、分类、

38
00:02:36,639 --> 00:02:40,399
分割或其他类型的目标

